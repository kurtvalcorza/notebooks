{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFtEeY13V5le"
      },
      "source": [
        "# Setup\n",
        "- Upload audio mp3 file/s to Google Drive\n",
        "- Change runtime type Hardware accelerator to T4 GPU\n",
        "- Install Whisper and mount Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNmYH7tsGWkU"
      },
      "source": [
        "# whisper-large-v3\n",
        "- [https://github.com/openai/whisper](https://github.com/openai/whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d6CY0USYMq8"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2-oYXJ64VDD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8f4c5a-0639-4bed-8c1b-1b83ed495e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-9js8h6kd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-9js8h6kd\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.6.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.8.86)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20250625) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=3c8feb53de63c72309c622ed86313a400ef005e6fc8594f6357d9576c64c1bf0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-us6lrlqz/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpoREdPV2bkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a62253c-3926-4c5b-aacc-3fe84efb1fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [00:45<00:00, 67.9MiB/s]\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:05.180]  Welcome to the deep dive. Today we're cutting through some of the noise around AI. It feels\n",
            "[00:05.180 --> 00:09.140]  like it's moving at warp speed, doesn't it? It really does. Constant headlines, new developments.\n",
            "[00:09.320 --> 00:13.460]  Exactly. And everyone's talking about AI, but, you know, are we all talking about the same thing?\n",
            "[00:13.900 --> 00:19.660]  Often we jump into these big discussions, maybe about regulation or ethics, without really having\n",
            "[00:19.660 --> 00:25.740]  a shared idea of what AI even fundamentally is. It's like trying to build something complex\n",
            "[00:25.740 --> 00:30.240]  without agreeing on the blueprint first. That's a great analogy. You need that shared\n",
            "[00:30.240 --> 00:34.600]  language. So our mission today is to dive deep into a really important document,\n",
            "[00:34.960 --> 00:40.520]  one that's trying to bring exactly that clarity. We're looking at the explanatory memorandum on\n",
            "[00:40.520 --> 00:46.880]  the updated OECD definition of an AI system. This just came out in March 2024. Right. And this isn't\n",
            "[00:46.880 --> 00:52.560]  just, you know, some academic exercise tucked away somewhere. This is from the OECD, the Organization\n",
            "[00:52.560 --> 00:55.560]  for Economic Cooperation and Development. They're a major international...\n",
            "[00:55.740 --> 00:58.080]  And why does their definition matter so much?\n",
            "[00:58.420 --> 01:03.960]  Well, because getting a shared definition is absolutely foundational. Think about global AI\n",
            "[01:03.960 --> 01:10.140]  governance, setting policy, even just understanding the research. If different countries or companies\n",
            "[01:10.140 --> 01:13.780]  mean different things by AI, it gets incredibly messy.\n",
            "[01:14.040 --> 01:14.240]  Okay.\n",
            "[01:14.800 --> 01:19.000]  So this document, this definition, it's trying to provide that common baseline.\n",
            "[01:19.420 --> 01:24.860]  It's vital for effective collaboration and, frankly, for sensible regulation down the line.\n",
            "[01:24.860 --> 01:25.640]  It's interesting.\n",
            "[01:25.740 --> 01:29.560]  You mentioned that because the title says updated definition. So you might be thinking,\n",
            "[01:29.840 --> 01:34.140]  hang on, didn't we sort of just get a handle on the last one? It feels like the terms keep shifting.\n",
            "[01:34.380 --> 01:36.020]  Yeah, that's a fair point. It can feel that way.\n",
            "[01:36.140 --> 01:36.260]  Okay.\n",
            "[01:36.600 --> 01:40.840]  This update clarifies the original 2019 OECD recommendation on AI.\n",
            "[01:41.520 --> 01:43.540]  People often call those the AI principles.\n",
            "[01:43.740 --> 01:44.320]  Oh, okay.\n",
            "[01:44.320 --> 01:48.080]  And this update is actually part of a standard five-year review process for those principles.\n",
            "[01:48.260 --> 01:48.380]  Right.\n",
            "[01:48.720 --> 01:52.740]  But what's really telling is that they decided to review the definition part\n",
            "[01:52.740 --> 01:54.180]  much earlier than the rest.\n",
            "[01:54.180 --> 01:55.720]  Oh, why the rush?\n",
            "[01:55.880 --> 01:57.860]  Just on the definition, that sounds quite deliberate.\n",
            "[01:58.200 --> 02:02.800]  It absolutely was. They accelerated the review of the definition specifically because it's so\n",
            "[02:02.800 --> 02:07.960]  fundamental. The goal was to help get broader alignment across different efforts happening\n",
            "[02:07.960 --> 02:10.460]  right now. I think places like the European Union, Japan.\n",
            "[02:10.780 --> 02:12.920]  Right. The EU AI Act, things like that.\n",
            "[02:12.980 --> 02:17.860]  Exactly. They're all deep in AI governance discussions too. So having a harmonized\n",
            "[02:17.860 --> 02:22.180]  definition helps create that truly shared language for the global conversation,\n",
            "[02:22.580 --> 02:24.180]  basically right now when it's most needed.\n",
            "[02:24.180 --> 02:25.700]  Okay. So to really get what's needed, we need to have a harmonized definition.\n",
            "[02:25.700 --> 02:25.720]  Okay. So to really get what's needed, we need to have a harmonized definition.\n",
            "[02:25.720 --> 02:31.380]  Let's look at the original first. Back in 2019, the OECD said an AI system was\n",
            "[02:31.380 --> 02:36.000]  a machine-based system that can, for a given set of human-defined objectives,\n",
            "[02:36.560 --> 02:40.740]  make predictions, recommendations, or decisions influencing real or virtual environments.\n",
            "[02:41.220 --> 02:44.340]  AI systems are designed to operate with varying levels of economy.\n",
            "[02:44.660 --> 02:45.940]  Pretty straightforward for the time.\n",
            "[02:46.120 --> 02:48.320]  Now let's jump to the new one, March 2024.\n",
            "[02:49.400 --> 02:55.460]  The updated definition is, an AI system is a machine-based system that, for explicit or\n",
            "[02:55.460 --> 03:00.940]  implicit objectives, infers, from the input it receives, how to generate outputs such as\n",
            "[03:00.940 --> 03:05.720]  predictions, content, recommendations, or decisions that can influence physical or virtual\n",
            "[03:05.720 --> 03:10.560]  environments. Different AI systems vary in their levels of autonomy and adaptiveness after\n",
            "[03:10.560 --> 03:11.040]  deployment.\n",
            "[03:11.360 --> 03:11.480]  Right.\n",
            "[03:11.920 --> 03:16.620]  Okay. Let's unpack this a bit for you listening. Comparing those two, what really jumps out to\n",
            "[03:16.620 --> 03:18.620]  you? What are the big shifts here? Maybe even surprising ones.\n",
            "[03:18.700 --> 03:23.820]  Well, the very first thing I think is that phrase, explicit or implicit objectives. That's a huge\n",
            "[03:23.820 --> 03:25.440]  change from just human-dominated systems to AI systems. And that's a huge change from just human-dominated\n",
            "[03:25.440 --> 03:25.780]  systems to AI systems. And that's a huge change from just human-dominated\n",
            "[03:25.780 --> 03:26.120]  objectives.\n",
            "[03:26.180 --> 03:28.160]  Implicit objectives. What does that mean exactly?\n",
            "[03:28.420 --> 03:33.540]  It acknowledges that AI systems don't always have goals we directly, explicitly program in.\n",
            "[03:33.940 --> 03:38.780]  Objectives can still be explicit and human-defined, of course, like the rules in a chess program.\n",
            "[03:38.820 --> 03:39.060]  Okay.\n",
            "[03:39.460 --> 03:43.780]  But they can also be implicit. Maybe they're implied by human-set rules, like a self-driving\n",
            "[03:43.780 --> 03:47.760]  system stopping at red lights implies the goal of avoiding accidents, right?\n",
            "[03:47.780 --> 03:48.300]  Makes sense.\n",
            "[03:48.300 --> 03:54.400]  Or, and this is really key for modern AI objectives, can be implicit in the training data.\n",
            "[03:54.840 --> 03:55.420]  Think about a large system.\n",
            "[03:55.440 --> 04:00.340]  Think about a large language model. You don't explicitly code be plausible, but it learns that\n",
            "[04:00.340 --> 04:05.240]  because it's rewarded for generating plausible-sounding text based on all the data it ingested.\n",
            "[04:05.600 --> 04:09.640]  Ah, so the objective kind of emerges from the training process itself.\n",
            "[04:09.780 --> 04:15.120]  Precisely. It's not always a neat line item in the code. And the definition also notes that\n",
            "[04:15.120 --> 04:19.680]  objectives aren't always fully known in advance, like with some recommender systems that figure\n",
            "[04:19.680 --> 04:21.260]  out your preferences through interaction.\n",
            "[04:21.640 --> 04:24.520]  And what about user prompts, like when I ask a chatbot a question?\n",
            "[04:24.520 --> 04:24.840]  Yes.\n",
            "[04:25.440 --> 04:31.520]  It mentions that too. User prompts like your destination in a GPS or your specific query to an\n",
            "[04:31.520 --> 04:36.160]  LLM, they supplement the system's built-in objectives during operation. They steer it.\n",
            "[04:36.240 --> 04:36.520]  Okay.\n",
            "[04:36.520 --> 04:41.780]  And this whole area connects to the challenge of misalignment. That's a big topic in AI safety.\n",
            "[04:42.260 --> 04:45.460]  It's when, you know, the objective you thought you set leads to unexpected,\n",
            "[04:45.620 --> 04:49.360]  maybe unwanted outcomes because it's hard to specify exactly what you intend.\n",
            "[04:49.580 --> 04:52.280]  Right. The paperclip maximizer idea taken to an extreme.\n",
            "[04:52.720 --> 04:55.400]  Sort of, yeah. Or just unintended biases creep.\n",
            "[04:55.440 --> 04:55.680]  Yeah.\n",
            "[04:55.680 --> 04:58.960]  And that's what we're moving in because the implicit objective learned from data wasn't quite right.\n",
            "[04:59.500 --> 05:03.640]  Another really obvious change is adding content as an output.\n",
            "[05:03.980 --> 05:05.980]  Ah, yes. That wasn't in the 2019 one.\n",
            "[05:06.120 --> 05:12.660]  Nope. That had predictions, recommendations, decisions. But with generative AI exploding text,\n",
            "[05:13.020 --> 05:21.000]  images, audio, video, it just makes total sense to explicitly name content as a primary type of output now.\n",
            "[05:21.140 --> 05:22.120]  It reflects reality.\n",
            "[05:22.260 --> 05:24.140]  Definitely. And the last big thing.\n",
            "[05:24.560 --> 05:25.200]  Adaptiveness.\n",
            "[05:25.680 --> 05:27.900]  This is completely new in the definition.\n",
            "[05:28.260 --> 05:32.980]  It refers mostly to machine learning systems that can keep learning and changing after they've been deployed.\n",
            "[05:33.300 --> 05:34.280]  So they learn on the fly.\n",
            "[05:34.560 --> 05:35.140]  Kind of, yeah.\n",
            "[05:35.640 --> 05:39.460]  They modify their behavior based on new input, new data they encounter in the real world.\n",
            "[05:39.580 --> 05:44.000]  Think about speech recognition getting better at understanding your specific accent over time.\n",
            "[05:44.080 --> 05:46.600]  Or my music recommendations getting spookily accurate.\n",
            "[05:46.640 --> 05:48.380]  Exactly. That's adaptiveness.\n",
            "[05:48.380 --> 05:53.080]  And the document even notes that some systems might develop abilities to perform new kinds of inference\n",
            "[05:53.080 --> 05:55.420]  that weren't even envisioned by the original program.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the input directory containing audio files\n",
        "input_dir = '/content'  #@param {type: \"string\"}\n",
        "\n",
        "# Iterate over audio files in the input directory\n",
        "for audio_file in os.listdir(input_dir):\n",
        "    if audio_file.endswith('.wav'):  # Adjust the file extension as needed\n",
        "        audio_path = os.path.join(input_dir, audio_file)\n",
        "\n",
        "        # Transcribe the audio file\n",
        "        !whisper \"{audio_path}\" --model large-v3 --output_dir \"{input_dir}\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}